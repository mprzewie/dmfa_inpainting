# 2021-05-17 17:03:37.462965
python train_wae.py --experiment_name=64x64/experiments_v5_long_training/dmfa_incomp_v2 --inpainter_type=dmfa --inpainter_path ../results/inpainting/celeba/fullconv/64x64/incomplete_data/dmfa_mse_10_eps_v5_train_det --batch_size 16 --dataset celeba --img_size 64 --mask_train_size 32 --mask_val_size 32 --num_epochs=50 --render_every 2 --lr=1e-4 --wae_fc=64 --wae_lc=64 --wae_depth=4 --wae_bl=4 --wae_latent_size=64 --wae_disc_hidden 512 --wae_recon_loss mse --dataset_root /mnt/users/mprzewiezlikowski/local/data/.data/ --max_benchmark_batches -1 --wae_disc_loss_weight 0.025
