{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions as dist\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import optim\n",
    "\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from torchvision import transforms as tr\n",
    "from torchvision.models import vgg11_bn\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pprint import pprint\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inpainting.datasets.mnist import train_val_datasets\n",
    "from inpainting.visualizations.digits import digit_with_mask as vis_digit_mask\n",
    "from inpainting.training import train_inpainter\n",
    "from inpainting.utils import classifier_experiment, inpainted, predictions_for_entire_loader\n",
    "import inpainting.visualizations.samples as vis\n",
    "from inpainting.datasets import mask_coding as mc\n",
    "from inpainting.datasets.utils import RandomRectangleMaskConfig\n",
    "from inpainting.custom_layers import Reshape\n",
    "from inpainting.losses import nll_masked_batch_loss, nll_masked_batch_loss_components, r2_masked_batch_loss, nll_masked_batch_loss_same_size_masks\n",
    "from inpainting.inpainters.mnist import MNISTLinearInpainter, MNISTConvolutionalInpainter\n",
    "from inpainting.inpainters.fullconv import FullyConvolutionalInpainter\n",
    "from inpainting import backbones as bkb\n",
    "from inpainting import losses2 as l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.facecolor'] = \"white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ps aux | grep mprzewie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = Path(\"../results/mnist/fullconv/28x28/32_2_32_no_latent_a_ampl_0.5_bl_2\")\n",
    "experiment_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_val = train_val_datasets(\n",
    "    Path.home() / \"uj/data/\",\n",
    "    mask_configs=[\n",
    "#         RandomRectangleMaskConfig(mc.UNKNOWN_LOSS, 28,28, 0,0),\n",
    "\n",
    "        RandomRectangleMaskConfig(mc.UNKNOWN_LOSS, 14, 14, 0,0),\n",
    "#         RandomRectangleMaskConfig(mc.UNKNOWN_NO_LOSS, 16,16, 0,0)\n",
    "    ],\n",
    "    ds_type=MNIST,\n",
    "    resize_size=(28,28),\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(15, 15))\n",
    "for i in range(100):\n",
    "    (x,j), y = ds_train[i]\n",
    "    ax = axes[i // 10, i%10]\n",
    "    ax.set_title(f\"{y}\")\n",
    "    vis_digit_mask(x, j,ax)\n",
    "train_fig = plt.gcf()\n",
    "train_fig.savefig(experiment_path / \"train.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=196\n",
    "dl_train = DataLoader(ds_train, batch_size, shuffle=True)\n",
    "dl_val = DataLoader(ds_val, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_noms = lambda x,j,p,m,a,d : nll_masked_batch_loss_components(\n",
    "    x,j,p,m,a,d\n",
    ")[\"log_noms\"]\n",
    "\n",
    "x_minus_means = lambda x,j,p,m,a,d : nll_masked_batch_loss_components(\n",
    "    x,j,p,m,a,d\n",
    ")[\"x_minus_means\"]\n",
    "\n",
    "mse = lambda x,j,p,m,a,d : nll_masked_batch_loss_components(\n",
    "    x,j,p,m,a,d\n",
    ")[\"x_minus_means_2\"]\n",
    "\n",
    "log_dets = lambda x,j,p,m,a,d : nll_masked_batch_loss_components(\n",
    "    x,j,p,m,a,d\n",
    ")[\"log_dets\"]\n",
    "\n",
    "log_2_pi = lambda x,j,p,m,a,d : nll_masked_batch_loss_components(\n",
    "    x,j,p,m,a,d\n",
    ")[\"log_2_pi\"]\n",
    "\n",
    "a_var = lambda x,j,p,m,a,d : a.var()\n",
    "a_mean = lambda x,j,p,m,a,d : a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "# device = torch.device(\"cpu\")\n",
    "# inpainter = MNISTLinearInpainter(n_mixes=1, hidden_size=2048)\n",
    "\n",
    "\n",
    "inpainter = FullyConvolutionalInpainter(\n",
    "    n_mixes=1, a_width=4, a_amplitude=0.5, c_h_w=(1, 28, 28), last_channels=32, \n",
    "    extractor=bkb.down_up_backbone(\n",
    "        (2, 28, 28),\n",
    "        depth=2,\n",
    "        first_channels=32, \n",
    "        last_channels=32,\n",
    "        kernel_size=5,\n",
    "        latent=False,\n",
    "        block_length=2,   \n",
    "    )\n",
    "#     extractor=bkb.UNet(\n",
    "#         input_nc=2,\n",
    "#         output_nc=32,\n",
    "#         ngf=32\n",
    "#     )\n",
    ")\n",
    "\n",
    "# inpainter = MNISTConvolutionalInpainter(a_amplitude=0.5, h_w=(32,32), last_channels=64)\n",
    "\n",
    "history = []\n",
    "\n",
    "\n",
    "opt = optim.Adam(inpainter.parameters(), lr=4e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "history = train_inpainter(\n",
    "    inpainter, \n",
    "    dl_train, \n",
    "    dl_val, \n",
    "    opt, \n",
    "    loss_fn =l2.nll_buffered, \n",
    "    n_epochs=200,\n",
    "    device=device,\n",
    "    history_start=history,\n",
    "    # tqdm_loader=True,\n",
    "    max_benchmark_batches=50,\n",
    "    losses_to_log=dict(\n",
    "        mse=l2.loss_factory(\n",
    "            gathering_fn=l2.buffered_gather_batch_by_mask_indices,\n",
    "            calc_fn=l2.mse\n",
    "        ),\n",
    "        nll=l2.nll_buffered, \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [\n",
    "#     h[\"losses\"]\n",
    "#     for h in history\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with (experiment_path / \"history_last_epoch.pkl\").open(\"wb\") as f:\n",
    "    history_tmp = history\n",
    "    pickle.dump(history[-1], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (experiment_path / \"inpainter.schema\").open(\"w\") as f:\n",
    "    print(inpainter, file=f)\n",
    "with (experiment_path / \"opt.schema\").open(\"w\") as f:\n",
    "    print(opt, file=f)\n",
    "\n",
    "torch.save(inpainter.state_dict(), experiment_path / \"inpainter.state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chckp = torch.load(experiment_path / \"inpainter.state\")\n",
    "chckp\n",
    "inpainter.load_state_dict(chckp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history[-1][\"losses\"][\"objective\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loss_name in set(history[0][\"losses\"].keys()):\n",
    "    for fold in [\"train\", \"val\"]:\n",
    "        \n",
    "        plt.plot(\n",
    "            list(range(len(history))),\n",
    "            [h[\"losses\"][loss_name][fold] for h in history],\n",
    "            label=fold\n",
    "        )\n",
    "    plt.title(loss_name)\n",
    "    plt.legend()\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(experiment_path / f\"history.{loss_name}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = 5\n",
    "\n",
    "row_length = vis.row_length(*list(zip(*history[0][\"sample_results\"][\"train\"]))[0])\n",
    "fig, axes = plt.subplots(\n",
    "    int(np.ceil(len(history) / skip)* 2), \n",
    "    row_length,\n",
    "    figsize=(20, 30)\n",
    ")\n",
    "\n",
    "\n",
    "for e, h in enumerate(history):\n",
    "    if e % skip !=0 and e != (len(history) -1):\n",
    "        continue\n",
    "    \n",
    "    for ax_no, fold in [(0,\"train\"), (1,\"val\")]:\n",
    "        x, j, p, m, a, d, y = [t[0] for t in  h[\"sample_results\"][fold]]\n",
    "        row_no = (e // skip)*2 + ax_no\n",
    "        print(m.mean(), m.min(), m.max())\n",
    "\n",
    "        vis.visualize_sample(\n",
    "            x, j, p, m, a, d, y, \n",
    "            ax_row=axes[row_no], \n",
    "            title_prefixes={\n",
    "                0: f\"{e} {fold} \",\n",
    "#                 1: f\"y_m = {y_masked_pred}\"\n",
    "            },\n",
    "            drawing_fn=vis_digit_mask\n",
    "        )\n",
    "\n",
    "epochs_fig = plt.gcf()\n",
    "epochs_fig.savefig(experiment_path / \"epochs_renders.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_path = experiment_path / \"epochs\"\n",
    "epochs_path.mkdir(exist_ok=True)\n",
    "skip = 5\n",
    "n_rows = 16\n",
    "\n",
    "for e, h in enumerate(history):\n",
    "    if e % skip !=0 and e != (len(history) -1):\n",
    "        continue\n",
    "    \n",
    "    for ax_no, fold in [(0,\"train\"), (1,\"val\")]:\n",
    "        \n",
    "        \n",
    "        row_length = vis.row_length(*list(zip(*h[\"sample_results\"][fold]))[0])\n",
    "\n",
    "        fig, axes = plt.subplots(\n",
    "            n_rows, \n",
    "            row_length,\n",
    "            figsize=(20, 30)\n",
    "        )\n",
    "\n",
    "        for row_no, (x, j, p, m ,a, d, y) in enumerate(list(zip(*h[\"sample_results\"][fold]))[:n_rows]):\n",
    "            vis.visualize_sample(\n",
    "                x, j, p, m, a, d, y, \n",
    "                ax_row=axes[row_no], \n",
    "                title_prefixes={\n",
    "                    0: f\"{e} {fold} \",\n",
    "#                     1: f\"y_m = {y_masked_pred}\"\n",
    "                },\n",
    "                drawing_fn=vis_digit_mask\n",
    "\n",
    "            )\n",
    "        \n",
    "        title = f\"{e}_{fold}\"\n",
    "        plt.suptitle(title)\n",
    "        plt.savefig(epochs_path / f\"{title}.png\")\n",
    "#       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, j, p, m, a, d, y= history[0][\"sample_results\"][\"train\"]\n",
    "plt.imshow(x[0][0])\n",
    "\n",
    "m[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with (experiment_path / \"history_last_epoch.pkl\").open(\"rb\") as f:\n",
    "    hist_last_epoch = pickle.load(f)\n",
    "\n",
    "# history = [hist_last_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_arrays_stats(\n",
    "    arrays, ax=None, stat_fns = [np.min, np.max, np.mean], markers=\".\"\n",
    "):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "    if isinstance(markers, str):\n",
    "        markers = [markers] * len(stat_fns)\n",
    "    \n",
    "    for fn, m in zip(stat_fns, markers):\n",
    "        ax.scatter(\n",
    "            range(len(arrays)),\n",
    "            [\n",
    "                fn(a) for a in arrays\n",
    "            ],\n",
    "            marker=m,\n",
    "            label=fn.__name__\n",
    "            \n",
    "        )\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in [\"val\"]:\n",
    "    x, j, p, m, a, d, y = hist_last_epoch[\"sample_results\"][fold]\n",
    "\n",
    "    a_resh = a.reshape(a.shape[0] * a.shape[1], a.shape[2], a.shape[3])\n",
    "    covs = a_resh.transpose(0, 2, 1) @ a_resh\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20, 25), nrows=5)\n",
    "    \n",
    "    ax[0].set_title(f\"m stats {fold}\")\n",
    "    plot_arrays_stats(\n",
    "        m, ax[0]\n",
    "    )\n",
    "        \n",
    "    samples = [\n",
    "        vis.gans_gmms_sample_no_d(x_, m_[0], a_[0], d_[0])\n",
    "        for (x_, m_, a_, d_) in zip(x, m ,a, d)\n",
    "    ]\n",
    "    \n",
    "    ax[1].set_title(\"samples stats\")\n",
    "    plot_arrays_stats(samples, ax[1])\n",
    "    \n",
    "    ax[2].set_title(f\"a stats {fold}\")\n",
    "    plot_arrays_stats(\n",
    "        a, ax[2]\n",
    "    )\n",
    "    \n",
    "    ax[3].set_title(f\"d stats {fold}\")\n",
    "    plot_arrays_stats(\n",
    "        d, ax[3]\n",
    "    )\n",
    "    \n",
    "    ax[4].set_title(f\"cov stats {fold}\")\n",
    "    plot_arrays_stats(\n",
    "        covs, ax[4]\n",
    "    )\n",
    "    [a.legend() for a in ax[:5]]\n",
    "    fig.savefig(experiment_path / f\"outputs_stats.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    cov_resh = covs[0].reshape(-1)\n",
    "    plt.hist(cov_resh, log=True, bins=100)\n",
    "    plt.title(f\"cov[0] hist {fold}\")\n",
    "    plt.show()\n",
    "    \n",
    "    cov = covs[0]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10), nrows=2)\n",
    "    eigs = np.linalg.eigvals(cov)\n",
    "    ax[0].scatter(range(len(eigs)), eigs)\n",
    "    ax[0].set_title(\"eigenvals of cov[0]\")\n",
    "\n",
    "    cov_d = cov + np.diag(d[0])\n",
    "    eigs_d = np.linalg.eigvals(cov_d)\n",
    "    ax[1].scatter(range(len(eigs_d)), eigs_d)\n",
    "    ax[1].set_title(\"eigenvals of cov[0] + d[0]\")\n",
    "    fig.savefig(experiment_path / \"eigenvals.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # wygląda na to, że mamy ~3 duże wartosci własne\n",
    "    \n",
    "    print(\"m analysis\")\n",
    "    \n",
    "    \n",
    "    plt.hist(d[0].reshape(-1), bins=100, log=True)\n",
    "    plt.title(\"d[0] hist\")\n",
    "    plt.show()\n",
    "    \n",
    "#     for i in range(3):\n",
    "#         plt.imshow(a_resh[0, i].reshape(28,28), cmap=\"gray\")\n",
    "#         plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next up\n",
    "# * różne aktywacje wyjścia macierzy A (sigmoid? różne zakresy?)\n",
    "# * wyplotować wielkość wartości własne A, D na przestrzeni treningu\n",
    "# spróbować trenowania na niepełnych danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results = predictions_for_entire_loader(\n",
    "    inpainter.to(torch.device(\"cpu\")),\n",
    "    dl_val,\n",
    "    torch.device(\"cpu\")\n",
    "    \n",
    ")\n",
    "with (experiment_path / \"val_predictions.pkl\").open(\"wb\") as f:\n",
    "    pickle.dump(val_results, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (experiment_path / \"val_predictions.pkl\").open(\"wb\") as f:\n",
    "    pickle.dump(val_results, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(10, 12, figsize=(15,15)\n",
    ")\n",
    "\n",
    "for i in range(10):\n",
    "    vis.visualize_sample(\n",
    "        *val_results[i],\n",
    "        drawing_fn=vis_digit_mask,\n",
    "        title_prefixes=dict(),\n",
    "        ax_row=ax[i]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('uj': conda)",
   "language": "python",
   "name": "python37064bitujconda26cc5d92af534893ad9de9cd64c222ba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
