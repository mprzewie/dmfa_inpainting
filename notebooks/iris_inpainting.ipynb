{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions as dist\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import optim\n",
    "\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from torchvision import transforms as tr\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150, 4), (150,), {0, 1, 2})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "\n",
    "J = np.random.uniform(size=X.shape)\n",
    "thresh = 0.2\n",
    "J[J < thresh] = 0\n",
    "J[J >= thresh] = 1\n",
    "\n",
    "X.shape, J.shape, y.shape, set(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, J_train, J_test, y_train, y_test = train_test_split(X, J, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = TensorDataset(\n",
    "    torch.Tensor(X_train), \n",
    "    torch.Tensor(J_train),\n",
    "    torch.Tensor(y_train).long()\n",
    ")\n",
    "\n",
    "ds_test = TensorDataset(\n",
    "    torch.Tensor(X_test), \n",
    "    torch.Tensor(J_test),\n",
    "    torch.Tensor(y_test).long()\n",
    ")\n",
    "\n",
    "batch_size=16\n",
    "dl_train = DataLoader(ds_train, batch_size, shuffle=True)\n",
    "dl_test = DataLoader(ds_test, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshaper(nn.Module):\n",
    "    def __init__(self, out_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.out_size = out_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x.view(*self.out_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisInpainter(\n",
    "    nn.Module\n",
    "):\n",
    "    def __init__(self, n_mixes: int = 1, in_size: int = 4, a_width = 3):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        self.extractor = nn.Sequential(\n",
    "            nn.Linear(in_size * 2, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.a_extractor = nn.Sequential(\n",
    "            nn.Linear(20, in_size * n_mixes * a_width),\n",
    "            Reshaper((-1, n_mixes, a_width, in_size,)) # * L, we don't want 1x4 vector but L x4 matrix))\n",
    "        )\n",
    "        self.m_extractor = nn.Sequential(\n",
    "            nn.Linear(20, n_mixes * in_size),\n",
    "            Reshaper((-1, n_mixes, in_size))\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.d_extractor = nn.Sequential(\n",
    "            nn.Linear(20, n_mixes * in_size),\n",
    "            Reshaper((-1, n_mixes, in_size))\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.p_extractor = nn.Sequential(\n",
    "            nn.Linear(20, n_mixes),\n",
    "            nn.Softmax()\n",
    "        ) # omit this, let's say p = 1 for now\n",
    "\n",
    "    def forward(self, X, J):\n",
    "        X_masked = X * J\n",
    "        X_J = torch.cat([X_masked, J], dim=1)\n",
    "        features = self.extractor(X_J)\n",
    "        m = self.m_extractor(features)\n",
    "        d = self.d_extractor(features)\n",
    "        p = self.p_extractor(features)\n",
    "        a = self.a_extractor(features)\n",
    "        \n",
    "        return  p, m, a, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nll_loss(X, J, P, M, A, D) -> torch.autograd.Variable:\n",
    "    zipped = zip(X, J, P, M, A, D)\n",
    "    losses = []\n",
    "    \n",
    "    \n",
    "    for i, (x, j, p, m, a, d) in enumerate(zipped):\n",
    "        mask_inds = (j==0).nonzero().squeeze()\n",
    "        x_masked = torch.index_select(x, 0, mask_inds)\n",
    "        a_masked = torch.index_select(a, 2, mask_inds)\n",
    "        m_masked, d_masked = [\n",
    "            torch.index_select(t, 1, mask_inds)\n",
    "            for t in [m, d]\n",
    "        ]\n",
    "        \n",
    "        for (p_i, m_i, d_i, a_i) in zip(p, m_masked, d_masked, a_masked):\n",
    "            if a_i.shape[1] > 0:\n",
    "                cov = (a_i.transpose(0,1) @ a_i) + torch.diag(d_i ** 2)\n",
    "                mvn_d = dist.MultivariateNormal(m_i, cov) # calculate this manually\n",
    "                l = - mvn_d.log_prob(x_masked) \n",
    "                losses.append(l)\n",
    "            else:\n",
    "                losses.append(torch.tensor(0.0, requires_grad=True)) #.cuda())\n",
    "    return torch.stack(losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/mprzewie/.anaconda3/envs/uj/lib/python3.7/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "100%|██████████| 100/100 [00:09<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9555, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inpainter = IrisInpainter()\n",
    "# inpainter = inpainter.cuda()\n",
    "opt = optim.Adam(inpainter.parameters(), lr=4e-3)\n",
    "n_epochs = 100\n",
    "train_hist = []\n",
    "val_hist = []\n",
    "for e in tqdm(range(n_epochs)):\n",
    "    inpainter.train()\n",
    "    train_losses = [] \n",
    "    for i, (x, j, y) in enumerate(dl_train):\n",
    "        inpainter.zero_grad()\n",
    "#         x, j = x.cuda(), j.cuda()\n",
    "        p, m, a, d = inpainter(x, j)\n",
    "        loss = nll_loss(x, j, p, m, a, d)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_losses.append(loss)\n",
    "    train_hist.append(torch.stack(train_losses).mean())\n",
    "    \n",
    "    inpainter.eval()\n",
    "    val_losses = []\n",
    "    for i, (x, j, y) in enumerate(dl_test):\n",
    "        inpainter.zero_grad()\n",
    "#         x, j = x.cuda(), j.cuda()\n",
    "\n",
    "        p, m, a, d = inpainter(x, j)\n",
    "        loss = nll_loss(x, j, p, m, a, d)\n",
    "        val_losses.append(loss)\n",
    "    val_hist.append(torch.stack(val_losses).mean())\n",
    "\n",
    "#     print(train_hist[-1], val_losses[-1])\n",
    "\n",
    "plt.plot(list(range(n_epochs)), train_hist, label=\"train\")\n",
    "plt.plot(list(range(n_epochs)), val_hist, label=\"val\")\n",
    "plt.legend()\n",
    "print(val_losses[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MLPClassifier((10, 20, 10, 4), learning_rate_init=4e-3, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "accuracy_score(classifier.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_masked = X_test * J_test\n",
    "# X_test_masked[:, 0][J_test[:,0] == 0] = X_train[:,0].mean()\n",
    "# X_test_masked[:, 1][J_test[:,1] == 0] = X_train[:,1].mean()\n",
    "# X_test_masked[:, 2][J_test[:,2] == 0] = X_train[:,2].mean()\n",
    "# X_test_masked[:, 3][J_test[:,3] == 0] = X_train[:,3].mean()\n",
    "\n",
    "\n",
    "accuracy_score(classifier.predict(X_test_masked), y_test)\n",
    "# print(X_train.mean(axis=0))\n",
    "# X_test_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test[0] [6.1 2.8 4.7 1.2]\n",
      "X_test_masked[0] [6.1 2.8 0.  1.2]\n",
      "M_test.detach().numpy()[0, 0] [3.5194266 2.2902582 4.3174076 1.1538798]\n",
      "X_test_inpainted[0] [6.1        2.8        4.31740761 1.2       ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mprzewie/.anaconda3/envs/uj/lib/python3.7/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_test, M_test, A_test, D_test = inpainter(torch.Tensor(X_test_masked), torch.Tensor(J_test))\n",
    "\n",
    "X_test_inpainted = X_test_masked.copy()\n",
    "X_test_inpainted[J_test == 0] = M_test.detach().cpu().numpy()[:, 0][J_test == 0]\n",
    "\n",
    "# X_test_inpainted = M_test.detach().cpu().numpy()[:, 0]\n",
    "print(\"X_test[0]\", X_test[0]), \n",
    "print(\"X_test_masked[0]\", X_test_masked[0]) \n",
    "print(\"M_test.detach().numpy()[0, 0]\", M_test.detach().cpu().numpy()[0, 0]) \n",
    "print(\"X_test_inpainted[0]\", X_test_inpainted[0])\n",
    "\n",
    "accuracy_score(classifier.predict(X_test_inpainted), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mprzewie/.anaconda3/envs/uj/lib/python3.7/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.2720, grad_fn=<MeanBackward0>),)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_test, M_test, A_test, D_test = inpainter(torch.Tensor(X_test_masked), torch.Tensor(J_test))\n",
    "#\n",
    "nll_loss(torch.tensor(X_test).float(), torch.tensor(J_test).float(), P_test, M_test, A_test, D_test), \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.3005e+00,  7.2704e-02, -4.5100e-01, -5.2212e-02],\n",
       "          [-2.7404e-01, -2.5629e-02, -5.2458e-01, -4.7878e-01],\n",
       "          [-8.1538e-01, -2.5143e-02, -4.0545e-01, -3.0611e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5902e+00,  5.3240e-02, -5.4854e-01, -5.3169e-02],\n",
       "          [-3.7253e-01,  5.8783e-02, -6.6487e-01, -5.2126e-01],\n",
       "          [-1.0240e+00, -4.7817e-02, -3.7985e-01, -3.2934e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0396e+00,  2.9345e-01,  6.1209e-01,  7.5713e-01],\n",
       "          [-6.5527e-01,  1.9479e-01, -1.7811e-01,  4.2216e-01],\n",
       "          [-7.7358e-01,  1.2367e-01, -3.6835e-01, -1.0461e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 5.6902e-01,  3.6508e-01,  2.4951e-01,  5.3692e-01],\n",
       "          [-1.7401e-01,  1.3008e-02, -1.7502e-01,  2.0281e-01],\n",
       "          [-4.6677e-01, -6.7784e-03, -1.7177e-01, -7.1533e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4137e+00,  5.3329e-02, -4.6394e-01, -6.2432e-02],\n",
       "          [-3.1895e-01, -1.1904e-02, -5.5372e-01, -4.9782e-01],\n",
       "          [-8.6999e-01, -5.1348e-03, -4.4724e-01, -3.3084e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5308e+00,  5.7525e-02, -5.3253e-01, -5.3189e-02],\n",
       "          [-3.4658e-01,  4.1819e-02, -6.3448e-01, -5.0980e-01],\n",
       "          [-9.7746e-01, -4.2451e-02, -3.8380e-01, -3.2521e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.8046e+00,  4.1257e-02, -5.4102e-01, -9.4178e-02],\n",
       "          [-4.6881e-01,  8.3815e-02, -7.5702e-01, -5.4972e-01],\n",
       "          [-1.1293e+00, -8.1757e-04, -4.6178e-01, -3.6902e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4005e+00,  2.1441e-01,  7.4162e-01,  3.2838e-01],\n",
       "          [-1.0040e+00,  4.2722e-01, -3.2005e-01,  4.1633e-01],\n",
       "          [-9.2438e-01,  9.3270e-02, -4.6867e-01, -6.2072e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9513e+00, -7.0589e-03, -6.3344e-01, -1.1656e-01],\n",
       "          [-5.0523e-01,  1.1508e-01, -7.4532e-01, -5.2647e-01],\n",
       "          [-1.2237e+00,  2.3808e-03, -3.9136e-01, -3.9328e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.6372e+00, -6.9853e-02, -7.5303e-01, -1.7469e-01],\n",
       "          [-3.2055e-01,  5.9920e-02, -3.7990e-01, -2.6925e-01],\n",
       "          [-1.0303e+00, -1.1548e-02, -1.6089e-02, -3.3832e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.1147e+00,  4.4731e-03, -5.6509e-01, -1.3407e-01],\n",
       "          [-6.1277e-01,  1.2988e-01, -8.6894e-01, -5.9619e-01],\n",
       "          [-1.3086e+00,  4.1960e-02, -5.3857e-01, -4.2197e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0461e+00,  1.2535e-01, -4.7850e-01, -6.2691e-03],\n",
       "          [-1.4876e-01, -2.6015e-02, -4.7995e-01, -4.2993e-01],\n",
       "          [-7.2346e-01, -1.1454e-01, -2.3171e-01, -2.3165e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1576e+00,  1.0616e-01, -4.8827e-01, -1.4901e-02],\n",
       "          [-2.0188e-01, -1.1687e-02, -5.1393e-01, -4.5356e-01],\n",
       "          [-7.8834e-01, -1.0020e-01, -2.6846e-01, -2.5275e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4364e+00,  7.5274e-02, -5.4318e-01, -3.8261e-02],\n",
       "          [-2.9436e-01,  3.8437e-02, -6.1168e-01, -4.8894e-01],\n",
       "          [-9.3477e-01, -7.0104e-02, -3.2637e-01, -3.0077e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4860e+00,  6.5477e-02, -5.1821e-01, -5.0300e-02],\n",
       "          [-3.3909e-01,  3.4994e-02, -6.2645e-01, -5.0649e-01],\n",
       "          [-9.6106e-01, -4.9890e-02, -3.7167e-01, -3.1467e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.3608e+00,  5.8891e-02, -4.1513e-01, -7.0983e-02],\n",
       "          [-3.2592e-01, -3.5166e-02, -5.3556e-01, -4.9808e-01],\n",
       "          [-8.3637e-01,  8.8772e-03, -4.7455e-01, -3.2772e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4175e+00,  1.8567e-01,  6.7820e-01,  2.0706e-01],\n",
       "          [-1.0048e+00,  4.3390e-01, -2.7912e-01,  4.1885e-01],\n",
       "          [-8.9565e-01,  8.1118e-02, -4.2395e-01, -5.3804e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1947e+00,  1.8736e-01,  5.6084e-01,  3.6447e-01],\n",
       "          [-8.2308e-01,  3.1362e-01, -2.5073e-01,  3.7739e-01],\n",
       "          [-8.0942e-01,  3.3705e-02, -3.6273e-01, -5.9694e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9002e+00,  4.2172e-02, -5.7300e-01, -9.7422e-02],\n",
       "          [-4.9943e-01,  1.1495e-01, -8.1453e-01, -5.6026e-01],\n",
       "          [-1.2011e+00, -1.0989e-02, -4.4430e-01, -3.7283e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.0056e+00, -4.7642e-02, -8.2431e-01, -1.4786e-01],\n",
       "          [-4.6133e-01,  1.6573e-01, -6.7776e-01, -4.1216e-01],\n",
       "          [-1.3114e+00, -5.2264e-02, -8.9636e-02, -3.7501e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 7.6467e-01,  3.3662e-01,  2.6669e-01,  3.2789e-01],\n",
       "          [-3.3015e-01,  1.2037e-01, -2.2931e-01,  2.2022e-01],\n",
       "          [-4.9778e-01, -4.5593e-02, -2.0730e-01, -5.4250e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.0245e+00,  1.7933e-02, -5.6282e-01, -1.2283e-01],\n",
       "          [-5.6871e-01,  1.1971e-01, -8.4075e-01, -5.7969e-01],\n",
       "          [-1.2604e+00,  2.5384e-02, -5.0474e-01, -4.0370e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4828e+00,  6.6434e-02, -5.1890e-01, -5.2159e-02],\n",
       "          [-3.3189e-01,  3.3180e-02, -6.2292e-01, -5.0248e-01],\n",
       "          [-9.5246e-01, -4.6516e-02, -3.7379e-01, -3.1584e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.1055e+00, -4.9574e-02, -6.4254e-01, -1.5777e-01],\n",
       "          [-6.0088e-01,  1.2462e-01, -7.5648e-01, -5.3100e-01],\n",
       "          [-1.3202e+00,  3.7723e-02, -4.0624e-01, -4.2614e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.0766e+00, -3.6950e-01, -1.2530e+00, -2.2743e-01],\n",
       "          [-4.0175e-01,  6.4421e-02, -1.2326e-01,  3.9646e-02],\n",
       "          [-1.4086e+00, -3.2950e-02,  4.9144e-01, -4.7065e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.1536e+00, -2.7008e-02, -5.8210e-01, -1.5346e-01],\n",
       "          [-6.3218e-01,  1.2335e-01, -8.2877e-01, -5.8058e-01],\n",
       "          [-1.3224e+00,  6.2386e-02, -5.3034e-01, -4.3951e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4252e+00,  5.6839e-02, -4.1776e-01, -7.9536e-02],\n",
       "          [-3.4007e-01, -2.0899e-02, -5.5364e-01, -4.9170e-01],\n",
       "          [-8.5275e-01,  2.3633e-02, -4.9689e-01, -3.3290e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9295e+00, -2.6162e-01, -9.5500e-01, -2.6026e-01],\n",
       "          [-4.4529e-01,  5.3462e-02, -2.1058e-01, -1.9300e-01],\n",
       "          [-1.2347e+00,  4.0455e-02,  1.4640e-01, -4.4070e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4248e+00,  7.2918e-02, -5.2286e-01, -4.4775e-02],\n",
       "          [-2.9693e-01,  2.5958e-02, -5.9855e-01, -4.8880e-01],\n",
       "          [-9.1584e-01, -5.5327e-02, -3.5207e-01, -3.0608e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4377e+00,  7.5569e-02, -5.3395e-01, -4.2165e-02],\n",
       "          [-2.9988e-01,  3.5193e-02, -6.1249e-01, -4.9009e-01],\n",
       "          [-9.3304e-01, -6.4530e-02, -3.3626e-01, -3.0257e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.3329e+00,  1.3221e-01, -4.8275e-01, -7.5336e-02],\n",
       "          [-2.4156e-01,  1.4301e-02, -6.2556e-01, -4.4223e-01],\n",
       "          [-8.4783e-01, -4.9791e-02, -3.1693e-01, -2.7875e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5852e+00,  4.9432e-02, -5.2011e-01, -5.9358e-02],\n",
       "          [-3.9184e-01,  4.7046e-02, -6.5853e-01, -5.2899e-01],\n",
       "          [-1.0188e+00, -3.4764e-02, -4.0923e-01, -3.3394e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2843e+00,  1.8588e-01,  6.3275e-01,  3.6424e-01],\n",
       "          [-9.1406e-01,  3.5169e-01, -2.7500e-01,  3.9592e-01],\n",
       "          [-8.6830e-01,  4.7013e-02, -4.0477e-01, -6.0951e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0650e+00,  1.6759e-01,  5.5817e-01,  7.1437e-01],\n",
       "          [-7.8717e-01,  1.6928e-01, -1.6564e-01,  4.2721e-01],\n",
       "          [-8.4714e-01,  1.0963e-02, -3.1103e-01, -8.8071e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 9.7633e-01,  2.6239e-01,  4.5121e-01,  4.4776e-01],\n",
       "          [-6.4989e-01,  1.8716e-01, -2.5919e-01,  2.8696e-01],\n",
       "          [-6.9739e-01, -2.3831e-02, -3.1912e-01, -6.2247e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.0323e+00, -2.8083e-02, -6.2566e-01, -1.3992e-01],\n",
       "          [-5.5898e-01,  1.1562e-01, -7.5314e-01, -5.3335e-01],\n",
       "          [-1.2678e+00,  2.8217e-02, -4.1940e-01, -4.1354e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9298e+00,  6.2534e-02, -6.8557e-01, -1.0658e-01],\n",
       "          [-4.3948e-01,  1.6368e-01, -8.4469e-01, -4.9745e-01],\n",
       "          [-1.2442e+00, -5.8445e-02, -2.7019e-01, -3.4734e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 9.9846e-01,  2.5025e-01,  4.6466e-01,  4.4076e-01],\n",
       "          [-6.7939e-01,  1.9782e-01, -2.6177e-01,  2.9314e-01],\n",
       "          [-7.1516e-01, -2.3125e-02, -3.2601e-01, -6.1119e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4537e+00,  6.9806e-02, -5.2416e-01, -4.4669e-02],\n",
       "          [-3.1824e-01,  3.3085e-02, -6.1467e-01, -4.9857e-01],\n",
       "          [-9.4322e-01, -5.8022e-02, -3.5388e-01, -3.0778e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0946e+00,  1.6672e-01, -4.4740e-01, -5.0500e-02],\n",
       "          [-1.6179e-01, -1.7304e-02, -5.5982e-01, -4.1136e-01],\n",
       "          [-7.4042e-01, -9.2536e-02, -2.3735e-01, -2.2775e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9795e+00, -7.6928e-03, -5.9172e-01, -1.3608e-01],\n",
       "          [-5.4921e-01,  1.0605e-01, -7.6220e-01, -5.3774e-01],\n",
       "          [-1.2397e+00,  2.5040e-02, -4.3300e-01, -4.0170e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9695e+00,  2.8221e-02, -5.4670e-01, -1.1318e-01],\n",
       "          [-5.5222e-01,  1.1140e-01, -8.3180e-01, -5.8078e-01],\n",
       "          [-1.2328e+00,  1.6857e-02, -5.0351e-01, -3.9297e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9841e+00,  3.2899e-02, -7.2740e-01, -1.1615e-01],\n",
       "          [-4.5518e-01,  1.7204e-01, -8.1982e-01, -4.8434e-01],\n",
       "          [-1.2797e+00, -5.5342e-02, -2.3610e-01, -3.5971e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4783e+00,  1.1551e-01, -5.1669e-01, -8.0822e-02],\n",
       "          [-2.9676e-01,  4.5980e-02, -6.8205e-01, -4.6614e-01],\n",
       "          [-9.3935e-01, -4.5760e-02, -3.3300e-01, -2.9884e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5213e+00,  6.1375e-02, -5.4096e-01, -4.6967e-02],\n",
       "          [-3.4262e-01,  4.7556e-02, -6.3936e-01, -5.0934e-01],\n",
       "          [-9.8448e-01, -5.5707e-02, -3.6192e-01, -3.1766e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1971e+00,  9.0592e-02, -4.5208e-01, -4.0298e-02],\n",
       "          [-2.2090e-01, -3.4991e-02, -4.9548e-01, -4.5670e-01],\n",
       "          [-7.6197e-01, -4.6622e-02, -3.5792e-01, -2.8314e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.3486e+00,  6.1891e-02, -4.3544e-01, -6.4549e-02],\n",
       "          [-3.0327e-01, -2.9975e-02, -5.3093e-01, -4.8948e-01],\n",
       "          [-8.2872e-01, -1.3261e-03, -4.5101e-01, -3.2292e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.1009e+00, -1.6693e-02, -6.2446e-01, -1.3748e-01],\n",
       "          [-5.9547e-01,  1.3831e-01, -8.2038e-01, -5.5892e-01],\n",
       "          [-1.3252e+00,  1.9618e-02, -4.3362e-01, -4.1329e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.7340e+00, -1.4014e-01, -9.3021e-01, -1.9627e-01],\n",
       "          [-2.9949e-01,  6.3063e-02, -2.9109e-01, -5.8061e-02],\n",
       "          [-1.1471e+00, -5.3212e-02,  2.6888e-01, -3.2794e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.3114e+00,  7.7826e-02,  1.0594e-01, -7.7740e-02],\n",
       "          [-7.8126e-01,  2.9455e-01, -2.3652e-01,  5.5635e-02],\n",
       "          [-8.4543e-01, -7.2128e-02, -3.2252e-01, -2.1225e-01]]]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1227, grad_fn=<MeanBackward0>),)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll_loss(torch.tensor(X_test).float(), torch.tensor(J_test).float(), P_test, torch.tensor(X_test).float().reshape(-1, 1, 4), A_test, D_test), \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uj)",
   "language": "python",
   "name": "uj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
