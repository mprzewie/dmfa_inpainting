{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions as dist\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import optim\n",
    "\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from torchvision import transforms as tr\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pprint import pprint\n",
    "from inpainting.custom_layers import Reshape\n",
    "from inpainting.losses import r2_masked_batch_loss, r2_total_batch_loss, nll_masked_batch_loss, _nll_masked_batch_loss\n",
    "from inpainting.inpainters.digits import DigitsLinearInpainter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dupa dupa dupa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inpainting.datasets.digits import train_val_datasets\n",
    "from inpainting.visualizations.digits import digit_with_mask as vis_digit_mask\n",
    "from inpainting.training import train_inpainter\n",
    "from inpainting.utils import classifier_experiment, inpainted\n",
    "from inpainting import losses2 as l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.facecolor'] = \"white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ps aux | grep mprzewie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !echo $CUDA_VISIBLE_DEVICES\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = Path(\"../results/digits/more_visualizations\")\n",
    "experiment_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_val = train_val_datasets()\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(15, 15))\n",
    "for i in range(100):\n",
    "    (x,j), y = ds_train[i]\n",
    "    ax = axes[i // 10, i%10]\n",
    "    ax.set_title(f\"{y}\")\n",
    "    vis_digit_mask(x, j,ax)\n",
    "train_fig = plt.gcf()\n",
    "train_fig.savefig(experiment_path / \"train.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLPClassifier((100, 200, 10,), learning_rate_init=4e-3, max_iter=1000).fit(ds_train.X.reshape(-1, 64), ds_train.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=8\n",
    "dl_train = DataLoader(ds_train, batch_size, shuffle=True)\n",
    "dl_val = DataLoader(ds_val, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_std = lambda x, j, p, m, a, d: m.std(dim=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "inpainter = DigitsLinearInpainter(bias=True, n_hidden_layers=3, n_mixes=1)\n",
    "opt = optim.Adam(inpainter.parameters(), lr=4e-3, weight_decay=0.)\n",
    "n_epochs = 3\n",
    "history = train_inpainter(\n",
    "    inpainter, \n",
    "    dl_train, \n",
    "    dl_val, \n",
    "    opt, \n",
    "#     loss_fn=l2.nll_buffered(9),\n",
    "    loss_fn=l2.nll_buffered,\n",
    "#     loss_fn=l2.nll_zero,\n",
    "    n_epochs=n_epochs,\n",
    "    losses_to_log=dict(\n",
    "        nll_zero=l2.nll_zero,\n",
    "        nll_buffered=l2.nll_buffered\n",
    "        \n",
    "    ),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[h[\"losses\"] for h in history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [\n",
    "#     (h[\"losses\"][\"objective\"][\"train\"] - h[\"losses\"][\"nll_ung\"][\"train\"], h[\"losses\"][\"objective\"][\"train\"] - h[\"losses\"][\"nll_ancient\"][\"train\"])\n",
    "\n",
    "#     for h in history\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (experiment_path / \"inpainter.schema\").open(\"w\") as f:\n",
    "    print(inpainter, file=f)\n",
    "\n",
    "# torch.save(inpainter.state_dict, experiment_path / \"inpainter.state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history[-1][\"losses\"][\"objective\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_tmp = history\n",
    "history = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loss_name in set(history[0][\"losses\"].keys()):\n",
    "    for fold in [\"train\", \"val\"]:\n",
    "        \n",
    "        plt.plot(\n",
    "            list(range(len(history))),\n",
    "            [h[\"losses\"][loss_name][fold] for h in history],\n",
    "            label=fold\n",
    "        )\n",
    "    plt.title(loss_name)\n",
    "    plt.legend()\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(experiment_path / f\"history.{loss_name}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inpainting.visualizations.samples as vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(zip(*history[0][\"sample_results\"][\"train\"]))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = 10\n",
    "\n",
    "row_length = vis.row_length(*list(zip(*history[0][\"sample_results\"][\"train\"]))[0])\n",
    "fig, axes = plt.subplots(\n",
    "    int(np.ceil(len(history) / skip)* 2), \n",
    "    row_length,\n",
    "    figsize=(20, 30)\n",
    ")\n",
    "\n",
    "\n",
    "for e, h in enumerate(history):\n",
    "    if e % skip !=0 and e != (len(history) -1):\n",
    "        continue\n",
    "    \n",
    "    for ax_no, fold in [(0,\"train\"), (1,\"val\")]:\n",
    "        x, j, p, m, a, d, y = [t[0] for t in  h[\"sample_results\"][fold]]\n",
    "        row_no = (e // skip)*2 + ax_no\n",
    "\n",
    "        vis.visualize_sample(\n",
    "            x, j, p, m, a, d, y, \n",
    "            ax_row=axes[row_no], \n",
    "            title_prefixes={\n",
    "                0: f\"{e} {fold} \",\n",
    "#                 1: f\"y_m = {y_masked_pred}\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "epochs_fig = plt.gcf()\n",
    "epochs_fig.savefig(experiment_path / \"epochs_renders.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_path = experiment_path / \"epochs\"\n",
    "epochs_path.mkdir(exist_ok=True)\n",
    "skip = 20\n",
    "n_rows = 16\n",
    "\n",
    "for e, h in enumerate(history):\n",
    "    if e % skip !=0 and e != (len(history) -1):\n",
    "        continue\n",
    "    \n",
    "    for ax_no, fold in [(0,\"train\"), (1,\"val\")]:\n",
    "        \n",
    "        \n",
    "        row_length = vis.row_length(*list(zip(*h[\"sample_results\"][fold]))[0])\n",
    "\n",
    "        fig, axes = plt.subplots(\n",
    "            n_rows, \n",
    "            row_length,\n",
    "            figsize=(20, 30)\n",
    "        )\n",
    "\n",
    "        for row_no, (x, j, p, m ,a, d, y) in enumerate(list(zip(*h[\"sample_results\"][fold]))[:n_rows]):\n",
    "            vis.visualize_sample(\n",
    "                x, j, p, m, a, d, y, \n",
    "                ax_row=axes[row_no], \n",
    "                title_prefixes={\n",
    "                    0: f\"{e} {fold} \",\n",
    "#                     1: f\"y_m = {y_masked_pred}\"\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        title = f\"{e}_{fold}\"\n",
    "        plt.suptitle(title)\n",
    "        plt.savefig(epochs_path / f\"{title}.png\")\n",
    "#         plt.show()\n",
    "            \n",
    "\n",
    "# epochs_fig = plt.gcf()\n",
    "# epochs_fig.savefig(experiment_path / \"epochs_renders.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling from the inpainter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_path = experiment_path / \"samples\"\n",
    "samples_path.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "samples = history[-1][\"sample_results\"]\n",
    "\n",
    "\n",
    "n_rows = 16\n",
    "\n",
    "for ax_no, fold in [(0,\"train\"), (1,\"val\")]:\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        n_rows, \n",
    "        3 + 3 * inpainter.n_mixes,\n",
    "        figsize=(20, 30)\n",
    "    )\n",
    "    X, J, P, M, A, D, Y = samples[fold]\n",
    "    P_, M_, A_, D_ = inpainter(\n",
    "        torch.tensor(X).to(device),\n",
    "        torch.tensor(J).to(device)\n",
    "    )\n",
    "    P_n, M_n, A_n, D_n = [\n",
    "        t.detach().cpu().numpy()\n",
    "        for t in \n",
    "        [P_, M_, A_, D_]\n",
    "    ]\n",
    "    \n",
    "    for row_no, (x, j, p, m ,a, d, y) in enumerate(list(zip(X, J, P_n, M_n, A_n, D_n, Y))[:n_rows]):\n",
    "        vis.visualize_distribution_samples(\n",
    "            x, j, p, m, a, d, y, \n",
    "            axes[row_no]\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uj)",
   "language": "python",
   "name": "uj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
