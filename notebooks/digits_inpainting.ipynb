{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions as dist\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import optim\n",
    "\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from torchvision import transforms as tr\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pprint import pprint\n",
    "from inpainting.custom_layers import Reshape\n",
    "from inpainting.losses import nll_batch_loss\n",
    "from inpainting.inpainters.digits import DigitsLinearInpainter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "X = digits['data']\n",
    "y = digits['target']\n",
    "\n",
    "J = []\n",
    "for i in range(X.shape[0]):\n",
    "    mask = np.ones((8,8))\n",
    "    m_height = 3\n",
    "    m_width = 3\n",
    "    m_x = np.random.randint(0, 8 - m_width)\n",
    "    m_y = np.random.randint(0, 8 - m_height)\n",
    "\n",
    "    mask[m_y:m_y+m_height, m_x:m_x+m_width] = 0\n",
    "    J.append(mask.reshape(-1))\n",
    "    \n",
    "J = np.vstack(J)\n",
    "    \n",
    "X = X / 16\n",
    "X.shape, J.shape, y.shape, set(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, J_train, J_test, y_train, y_test = train_test_split(X, J, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_digit_mask(x, j, ax= None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "    \n",
    "    x_j = x *j\n",
    "    vis = np.vstack([x_j, x_j, x_j + (j==0)]).T.reshape(8,8,3) \n",
    "    \n",
    "    ax.imshow(vis)\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 10, figsize=(15, 15))\n",
    "for i in range(100):\n",
    "    ax = axes[i // 10, i%10]\n",
    "    ax.set_title(f\"{y_train[i]}\")\n",
    "    vis_digit_mask(X_train[i], J_train[i],ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = TensorDataset(\n",
    "    torch.Tensor(X_train), \n",
    "    torch.Tensor(J_train),\n",
    "    torch.Tensor(y_train).long()\n",
    ")\n",
    "\n",
    "ds_test = TensorDataset(\n",
    "    torch.Tensor(X_test), \n",
    "    torch.Tensor(J_test),\n",
    "    torch.Tensor(y_test).long()\n",
    ")\n",
    "\n",
    "batch_size=16\n",
    "dl_train = DataLoader(ds_train, batch_size, shuffle=True)\n",
    "dl_test = DataLoader(ds_test, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_loss(X, J, P, M, A, D) -> torch.autograd.Variable:\n",
    "    zipped = zip(X, J, P, M, A, D)\n",
    "    losses = []\n",
    "    \n",
    "    \n",
    "    for i, (x, j, p, m, a, d) in enumerate(zipped):\n",
    "        mask_inds = (j==0).nonzero().squeeze()\n",
    "        x_masked = torch.index_select(x, 0, mask_inds)\n",
    "        a_masked = torch.index_select(a, 2, mask_inds)\n",
    "        m_masked, d_masked = [\n",
    "            torch.index_select(t, 1, mask_inds)\n",
    "            for t in [m, d]\n",
    "        ]\n",
    "        \n",
    "        for (p_i, m_i, d_i, a_i) in zip(p, m_masked, d_masked, a_masked):\n",
    "            if a_i.shape[1] > 0:\n",
    "                cov = (a_i.T @ a_i) + torch.diag(d_i ** 2)\n",
    "                mvn_d = dist.MultivariateNormal(m_i, cov) # calculate this manually\n",
    "                l = - mvn_d.log_prob(x_masked) \n",
    "                losses.append(l)\n",
    "            else:\n",
    "                losses.append(torch.autograd.Variable(torch.tensor(0.0), requires_grad=True))\n",
    "    return torch.stack(losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpainter = DigitsLinearInpainter()\n",
    "# inpainter = inpainter.cuda()\n",
    "opt = optim.Adam(inpainter.parameters(), lr=4e-3)\n",
    "n_epochs = 50\n",
    "train_hist = []\n",
    "val_hist = []\n",
    "for e in tqdm(range(n_epochs)):\n",
    "    inpainter.train()\n",
    "    train_losses = [] \n",
    "    for i, (x, j, y) in enumerate(dl_train):\n",
    "        inpainter.zero_grad()\n",
    "#         x, j = x.cuda(), j.cuda()\n",
    "        p, m, a, d = inpainter(x, j)\n",
    "        loss = ((x - m[:, 0, :]) **2).mean()\n",
    "#         loss = nll_loss(x, j, p, m, a, d)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_losses.append(loss)\n",
    "    train_hist.append(torch.stack(train_losses).mean())\n",
    "    \n",
    "    inpainter.eval()\n",
    "    val_losses = []\n",
    "    for i, (x, j, y) in enumerate(dl_test):\n",
    "        inpainter.zero_grad()\n",
    "#         x, j = x.cuda(), j.cuda()\n",
    "        p, m, a, d = inpainter(x, j)\n",
    "        loss = ((x - m[:, 0, :]) **2).mean()\n",
    "\n",
    "#         loss = nll_loss(x, j, p, m, a, d)\n",
    "        val_losses.append(loss)\n",
    "    val_hist.append(torch.stack(val_losses).mean())\n",
    "\n",
    "#     print(train_hist[-1], val_losses[-1])\n",
    "plt.plot(list(range(n_epochs)), train_hist, label=\"train\")\n",
    "plt.plot(list(range(n_epochs)), val_hist, label=\"val\")\n",
    "plt.legend()\n",
    "print(train_hist[-1], val_hist[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLPClassifier((100, 200, 10,), learning_rate_init=4e-3, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "accuracy_score(classifier.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_masked = X_test * J_test\n",
    "y_test_masked_pred = classifier.predict(X_test_masked)\n",
    "\n",
    "accuracy_score(y_test_masked_pred, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_test, M_test, A_test, D_test = inpainter(torch.Tensor(X_test_masked), torch.Tensor(J_test))\n",
    "\n",
    "X_test_inpainted = X_test_masked.copy()\n",
    "X_test_inpainted[J_test == 0] = M_test.detach().cpu().numpy()[:, 0][J_test == 0]\n",
    "\n",
    "# print(\"X_test[0]\", X_test[0]), \n",
    "# print(\"X_test_masked[0]\", X_test_masked[0]) \n",
    "# print(\"M_test.detach().numpy()[0, 0]\", M_test.detach().cpu().numpy()[0, 0]) \n",
    "# print(\"X_test_inpainted[0]\", X_test_inpainted[0])\n",
    "y_test_inp_pred = classifier.predict(X_test_inpainted)\n",
    "accuracy_score(y_test_inp_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 5 + A_test.shape[2], figsize=(15, 15))\n",
    "for i in range(10):\n",
    "    \n",
    "    ax = axes[i, 0]\n",
    "    ax.set_title(f\"gt = {y_test[i]}\")\n",
    "    ax.imshow(X_test[i].reshape(8,8), cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    axes[i,1].set_title(f\"masked pred = {y_test_masked_pred[i]}\")\n",
    "    vis_digit_mask(X_test[i], J_test[i], ax=axes[i, 1])\n",
    "    \n",
    "    ax = axes[i, 2]\n",
    "    ax.set_title(f\"inp pred = {y_test_inp_pred[i]}\")\n",
    "    ax.imshow(X_test_inpainted[i].reshape(8,8), cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "#     vis_digit_mask(X_train[i], J_train[i],ax)\n",
    "    \n",
    "    ax = axes[i, 3]\n",
    "    ax.set_title(f\"M\")\n",
    "    ax.imshow(M_test[i, 0].reshape(8,8).detach().numpy(), cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    ax = axes[i, 4]\n",
    "    ax.set_title(f\"D\")\n",
    "    ax.imshow(D_test[i, 0].reshape(8,8).detach().numpy(), cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    for j in range(A_test.shape[2]):\n",
    "        ax = axes[i, 5 + j]\n",
    "        ax.set_title(f\"A[{j}]\")\n",
    "        ax.imshow(A_test[i, 0, j].reshape(8,8).detach().numpy(), cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "        f, a = ax.subplots(3,3)\n",
    "plt.suptitle(\"Test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_masked = X_train * J_train\n",
    "\n",
    "P_train, M_train, A_train, D_train = inpainter(torch.Tensor(X_train_masked), torch.Tensor(J_train))\n",
    "y_train_masked_pred = classifier.predict(X_train_masked)\n",
    "\n",
    "\n",
    "X_train_inpainted = X_train_masked.copy()\n",
    "X_train_inpainted[J_train == 0] = M_train.detach().cpu().numpy()[:, 0][J_train == 0]\n",
    "\n",
    "# print(\"X_test[0]\", X_test[0]), \n",
    "# print(\"X_test_masked[0]\", X_test_masked[0]) \n",
    "# print(\"M_test.detach().numpy()[0, 0]\", M_test.detach().cpu().numpy()[0, 0]) \n",
    "# print(\"X_test_inpainted[0]\", X_test_inpainted[0])\n",
    "y_train_inp_pred = classifier.predict(X_train_inpainted)\n",
    "\n",
    "fig, axes = plt.subplots(10, 5 + A_train.shape[2], figsize=(15, 15))\n",
    "for i in range(10):\n",
    "    \n",
    "    ax = axes[i, 0]\n",
    "    ax.set_title(f\"gt = {y_train[i]}\")\n",
    "    ax.imshow(X_train[i].reshape(8,8), cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    axes[i,1].set_title(f\"masked pred = {y_test_masked_pred[i]}\")\n",
    "    vis_digit_mask(X_train[i], J_train[i], ax=axes[i, 1])\n",
    "    \n",
    "    ax = axes[i, 2]\n",
    "    ax.set_title(f\"inp pred = {y_test_inp_pred[i]}\")\n",
    "    ax.imshow(X_train_inpainted[i].reshape(8,8), cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "#     vis_digit_mask(X_train[i], J_train[i],ax)\n",
    "    \n",
    "    ax = axes[i, 3]\n",
    "    ax.set_title(f\"M\")\n",
    "    ax.imshow(M_train[i, 0].reshape(8,8).detach().numpy(), cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    ax = axes[i, 4]\n",
    "    ax.set_title(f\"D\")\n",
    "    ax.imshow(D_train[i, 0].reshape(8,8).detach().numpy(), cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    for j in range(A_test.shape[2]):\n",
    "        ax = axes[i, 5 + j]\n",
    "        ax.set_title(f\"A[{j}]\")\n",
    "        ax.imshow(A_train[i, 0, j].reshape(8,8).detach().numpy(), cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "plt.suptitle(\"Train\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
