{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions as dist\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import optim\n",
    "\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from torchvision import transforms as tr\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pprint import pprint\n",
    "from inpainting.custom_layers import Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mask_fn(mask_shape):\n",
    "    h, w = mask_shape\n",
    "    def tensor_to_tensor_with_random_mask(image_tensor):\n",
    "        sx, sy = image_tensor.shape[1:]\n",
    "        mask = np.ones((1, sx, sy))\n",
    "        x, y = np.random.randint([0,0], [sx - h, sy - w])\n",
    "        mask[0, x:x+h, y:y+w] = 0\n",
    "        return (image_tensor, torch.tensor(mask).float())\n",
    "    return tensor_to_tensor_with_random_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_image_with_mask(image_tensor, mask_tensor, ax= None):\n",
    "    image_np = image_tensor.cpu().numpy().squeeze()\n",
    "    mask_np = mask_tensor.cpu().numpy()\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "    \n",
    "    image_masked = image_np * mask_np\n",
    "    print()\n",
    "    \n",
    "    vis = np.vstack([\n",
    "        image_masked, image_masked, image_masked + (mask_np == 0)\n",
    "    ]).transpose(1,2,0)\n",
    "    \n",
    "    ax.imshow(vis, cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tr.Compose([\n",
    "    tr.ToTensor(),\n",
    "    tr.Lambda(random_mask_fn((5,5)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = MNIST(\"../data\", train=True, download=True, transform=transform)\n",
    "ds_test = MNIST(\"../data\", train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ex, cls = ds_train[0]\n",
    "vis_image_with_mask(*ex)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "dl_train = DataLoader(ds_train, batch_size, shuffle=True)\n",
    "dl_test = DataLoader(ds_test, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTInpainter(\n",
    "    nn.Module\n",
    "):\n",
    "    def __init__(self, n_mixes: int = 1, in_size: int = 784, a_width = 3):\n",
    "        super().__init__()\n",
    "\n",
    "        extractor_out_size = 512\n",
    "        self.extractor = nn.Sequential(\n",
    "            Reshape((-1, in_size * 2)),\n",
    "            nn.Linear(in_size * 2, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, extractor_out_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.a_extractor = nn.Sequential(\n",
    "            nn.Linear(extractor_out_size, in_size * n_mixes * a_width),\n",
    "            Reshape((-1, n_mixes, a_width, in_size,)) # * L, we don't want 1x4 vector but L x4 matrix))\n",
    "        )\n",
    "        self.m_extractor = nn.Sequential(\n",
    "            nn.Linear(extractor_out_size, n_mixes * in_size),\n",
    "            Reshape((-1, n_mixes, in_size)),\n",
    "            nn.Sigmoid()\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.d_extractor = nn.Sequential(\n",
    "            nn.Linear(extractor_out_size, n_mixes * in_size),\n",
    "            Reshape((-1, n_mixes, in_size))\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.p_extractor = nn.Sequential(\n",
    "            nn.Linear(extractor_out_size, n_mixes),\n",
    "            nn.Softmax()\n",
    "        ) # omit this, let's say p = 1 for now\n",
    "\n",
    "    def forward(self, X, J):\n",
    "        X_masked = X * J\n",
    "        X_J = torch.cat([X_masked, J], dim=1)\n",
    "        features = self.extractor(X_J)\n",
    "        m = self.m_extractor(features)\n",
    "        d = self.d_extractor(features)\n",
    "        p = self.p_extractor(features)\n",
    "        a = self.a_extractor(features)\n",
    "        \n",
    "        return  p, m, a, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nll_loss(X, J, P, M, A, D) -> torch.autograd.Variable:\n",
    "    X = X.reshape(-1, 784)\n",
    "    J = J.reshape(-1, 784)\n",
    "    zipped = zip(X, J, P, M, A, D)\n",
    "    losses = []\n",
    "    \n",
    "    for i, (x, j, p, m, a, d) in enumerate(zipped):\n",
    "        mask_inds = (j==0).nonzero().squeeze()\n",
    "        x_masked = torch.index_select(x, 0, mask_inds)\n",
    "\n",
    "        \n",
    "        a_masked = torch.index_select(a, 2, mask_inds)\n",
    "        m_masked, d_masked = [\n",
    "            torch.index_select(t, 1, mask_inds)\n",
    "            for t in [m, d]\n",
    "        ]\n",
    "        \n",
    "        for (p_i, m_i, d_i, a_i) in zip(p, m_masked, d_masked, a_masked):\n",
    "            if a_i.shape[1] > 0:\n",
    "                cov = (a_i.transpose(0, 1) @ a_i) + torch.diag(d_i ** 2)\n",
    "                mvn_d = dist.MultivariateNormal(m_i, cov) # calculate this manually\n",
    "                l = - mvn_d.log_prob(x_masked) \n",
    "                losses.append(l)\n",
    "            else:\n",
    "                losses.append(torch.autograd.Variable(torch.tensor(0.0), requires_grad=True))\n",
    "    return torch.stack(losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 1/100 [07:19<12:04:59, 439.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 2/100 [14:53<12:04:43, 443.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6291cc386f2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minpainter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-21f5e56439ff>\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(X, J, P, M, A, D)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ma_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0ma_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_i\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mmvn_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# calculate this manually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmvn_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_masked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/uj/lib/python3.7/site-packages/torch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, covariance_matrix, precision_matrix, scale_tril, validate_args)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprecision_matrix\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unbroadcasted_scale_tril\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inpainter = MNISTInpainter()\n",
    "inpainter = inpainter.cuda()\n",
    "opt = optim.Adam(inpainter.parameters(), lr=4e-3)\n",
    "n_epochs = 100\n",
    "train_hist = []\n",
    "val_hist = []\n",
    "for e in tqdm(range(n_epochs)):\n",
    "    inpainter.train()\n",
    "    train_losses = [] \n",
    "    for i, ((x, j), y) in enumerate(dl_train):\n",
    "        inpainter.zero_grad()\n",
    "        x, j = x.cuda(), j.cuda()\n",
    "        p, m, a, d = inpainter(x, j)\n",
    "        loss = nll_loss(x, j, p, m, a, d)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_losses.append(loss)\n",
    "\n",
    "    train_hist.append(torch.stack(train_losses).mean())\n",
    "    \n",
    "    inpainter.eval()\n",
    "    val_losses = []\n",
    "    for i, ((x, j), y) in enumerate(dl_test):\n",
    "        inpainter.zero_grad()\n",
    "        x, j = x.cuda(), j.cuda()\n",
    "        p, m, a, d = inpainter(x, j)\n",
    "        loss = nll_loss(x, j, p, m, a, d)\n",
    "        val_losses.append(loss)\n",
    "    val_hist.append(torch.stack(val_losses).mean())\n",
    "\n",
    "#     print(train_hist[-1], val_losses[-1])\n",
    "\n",
    "plt.plot(list(range(n_epochs)), train_hist, label=\"train\")\n",
    "plt.plot(list(range(n_epochs)), val_hist, label=\"val\")\n",
    "plt.legend()\n",
    "print(val_losses[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLPClassifier((100, 200, 10,), learning_rate_init=4e-3, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "accuracy_score(classifier.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_masked = X_test * J_test\n",
    "accuracy_score(classifier.predict(X_test_masked), y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_test, M_test, A_test, D_test = inpainter(torch.Tensor(X_test_masked).cuda(), torch.Tensor(J_test).cuda())\n",
    "\n",
    "X_test_inpainted = X_test_masked.copy()\n",
    "X_test_inpainted[J_test == 0] = M_test.detach().cpu().numpy()[:, 0][J_test == 0]\n",
    "\n",
    "# print(\"X_test[0]\", X_test[0]), \n",
    "# print(\"X_test_masked[0]\", X_test_masked[0]) \n",
    "# print(\"M_test.detach().numpy()[0, 0]\", M_test.detach().cpu().numpy()[0, 0]) \n",
    "# print(\"X_test_inpainted[0]\", X_test_inpainted[0])\n",
    "accuracy_score(classifier.predict(X_test_inpainted), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 3, figsize=(15, 15))\n",
    "for i in range(10):\n",
    "    \n",
    "    ax = axes[i, 0]\n",
    "    ax.set_title(f\"{y_test[i]}\")\n",
    "    ax.imshow(X_test[i].reshape(8,8), cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "    vis_digit_mask(X_test[i], J_test[i], ax=axes[i, 1])\n",
    "    \n",
    "    ax = axes[i, 2]\n",
    "    ax.imshow(X_test_inpainted[i].reshape(8,8), cmap=\"gray\")\n",
    "#     vis_digit_mask(X_train[i], J_train[i],ax)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uj",
   "language": "python",
   "name": "uj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
